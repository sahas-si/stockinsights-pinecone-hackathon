{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6fb45ab3",
   "metadata": {},
   "source": [
    "# Get News Articles from RSS Feeds"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3370d43e",
   "metadata": {},
   "source": [
    "### RSS Feeds of Top News Channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0514f0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2fe33bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CSV as DataFrame\n",
    "df_feeds = pd.read_csv('rss_urls.csv')\n",
    "\n",
    "# Convert DataFrame to JSON\n",
    "rss_feeds = df_feeds.to_json(orient='records')\n",
    "\n",
    "json_feeds = json.loads(rss_feeds)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "234df7a8",
   "metadata": {},
   "source": [
    "### Parse RSS Feeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b6e6e23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import feedparser\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8f8b520b",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ganesh/anaconda3/lib/python3.10/site-packages/bs4/__init__.py:435: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "news_items = []\n",
    "\n",
    "for feed in json_feeds:\n",
    "    publisher_name = feed['Publisher Name']\n",
    "    rss_feed_url = feed['RSS Feed Link']\n",
    "    placeholder_imageUrl = feed['Publiser Image']\n",
    "\n",
    "    # Parse RSS feed\n",
    "    feed_data = feedparser.parse(rss_feed_url)\n",
    "\n",
    "    # Extract relevant data and store in a list of dictionaries\n",
    "    for entry in feed_data.entries:\n",
    "        news_item = {\n",
    "            \"header\": entry.title,\n",
    "            \"sourceUrl\": entry.link,\n",
    "            \"publisher\": publisher_name,\n",
    "            \"publishedOn\": entry.published,\n",
    "            \"description\": BeautifulSoup(entry.summary, 'html.parser').get_text()\n",
    "        }\n",
    "        \n",
    "        # Check if the entry has media content (thumbnail image)\n",
    "        if 'media_content' in entry:\n",
    "            news_item[\"imageUrl\"] = entry.media_content[0][\"url\"]\n",
    "        else:\n",
    "            news_item[\"imageUrl\"] = placeholder_imageUrl\n",
    "        news_items.append(news_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d65c062d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame for the current feed\n",
    "df = pd.DataFrame(news_items)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "64a0f8d9",
   "metadata": {},
   "source": [
    "# Get Stocks Mapped from PineCone Index and Sentiment via OpenAI"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "72362b62",
   "metadata": {},
   "source": [
    "#### PineCone Index has the context about the stocks embedded in some format via their earnings call transcripts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4b84f11b",
   "metadata": {},
   "source": [
    "### Pinecone Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0eb790c9",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ganesh/anaconda3/lib/python3.10/site-packages/pinecone/index.py:4: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import pinecone\n",
    "\n",
    "pinecone.init(api_key=\"\", environment=\"\")\n",
    "index=pinecone.Index(\"\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0a6ec9d4",
   "metadata": {},
   "source": [
    "### OpenAI Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c677d799",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "# Set up your OpenAI API credentials\n",
    "openai.api_key = ''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "29b58603",
   "metadata": {},
   "source": [
    "### Using Query Retrieval Chain from Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e1ea2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.vectorstores import Pinecone\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "Just output which companies will have an impact due to the news. \n",
    "\n",
    "News: {question}\n",
    "=========\n",
    "{context}\n",
    "=========\n",
    "\n",
    "Reply only with the below pattern of JSON. Do not add any text as reply. If there is no answer, reply with empty object. Reply only the JSON object and nothing else. \n",
    "[{{ \"company\":\"company_name\", \"sentiment\": \"neutral\"}}]\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "text_field = \"text\"\n",
    "\n",
    "embed = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-ada-002\",\n",
    "    openai_api_key=openai.api_key\n",
    ")\n",
    "\n",
    "vectorstore = Pinecone(\n",
    "    index, embed.embed_query, text_field\n",
    ")\n",
    "\n",
    "# chat completion llm\n",
    "llm = ChatOpenAI(\n",
    "    openai_api_key=openai.api_key,\n",
    "    model_name='gpt-3.5-turbo',\n",
    "    temperature=0.0\n",
    ")\n",
    "\n",
    "chain_type_kwargs = {\"prompt\": PROMPT}\n",
    "\n",
    "# retrieval qa chain\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=vectorstore.as_retriever(search_kwargs={'filter': {'country':'US', 'quarter': {'$in': ['Q42022','Q12023']}}}),\n",
    "    chain_type_kwargs=chain_type_kwargs,\n",
    "    return_source_documents=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438aa0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def apply_qa(row):\n",
    "    query = 'Headline: '+ row['header'] + '\\n'+ 'Summary: '+ row ['description']\n",
    "    result = qa({\"query\": query})\n",
    "    return result['result']\n",
    "\n",
    "# Count the total number of rows\n",
    "total_rows = len(df)\n",
    "\n",
    "# Initialize a progress bar\n",
    "progress_bar = tqdm(total=total_rows, desc=\"Processing\")\n",
    "\n",
    "# Iterate over each row in the DataFrame\n",
    "for index, row in df.iterrows():\n",
    "    # Apply the qa() function to the concatenated query and store the result in the 'companySentiment' column\n",
    "    df.loc[index, 'companySentiment'] = apply_qa(row)\n",
    "    \n",
    "    # Update the progress bar\n",
    "    progress_bar.update(1)\n",
    "    \n",
    "    # Add a time gap between each iteration (e.g., 1 second)\n",
    "    time.sleep(1)\n",
    "\n",
    "# Close the progress bar\n",
    "progress_bar.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bed182f8",
   "metadata": {},
   "source": [
    "# Filter out Articles using OpenAI\n",
    "##### This is to keep the list of articles more focussed. Based on OpenAI's interpretation of News' impact on markets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd55c535",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "\n",
    "You are a helpful assistant. You provide an impact score when I share a news article title and short summary based on how much impact the news can have on capital markets.You rate the scores 0 to 10 based on level of impact.\n",
    "\n",
    "\n",
    "News \n",
    "=========\n",
    "{text}\n",
    "=========\n",
    "\n",
    "\n",
    "Reply only with the below pattern of JSON. Do not add any text as reply. If there is no answer, reply with empty object. Reply only the JSON object and nothing else. \n",
    "{{\"impact_score\":\"\"}}\n",
    "\"\"\"\n",
    "PROMPT = PromptTemplate(template=prompt_template, input_variables=[\"text\"])\n",
    "\n",
    "# chat completion llm\n",
    "llm = ChatOpenAI(\n",
    "    openai_api_key=openai.api_key,\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    temperature=0.0\n",
    ")\n",
    "\n",
    "chain = load_summarize_chain(llm, chain_type=\"stuff\", prompt=PROMPT)\n",
    "\n",
    "\n",
    "text = 'Headline: '+ 'Russia-Ukraine war live: Putin says those behind ‘armed rebellion’ will be punished;' + '\\n' + 'Summary: ' + 'Wagner chief says he’s in Rostov military HQ – latest updates - '\n",
    "\n",
    "result = chain.run([Document(page_content=text)])\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fddda86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def apply_qa(row):\n",
    "    text = 'Headline: '+ row['header'] + '\\n'+ 'Summary: '+ row ['description']\n",
    "    result = chain.run([Document(page_content=text)])\n",
    "    return result\n",
    "\n",
    "# Count the total number of rows\n",
    "total_rows = len(df)\n",
    "\n",
    "# Initialize a progress bar\n",
    "progress_bar = tqdm(total=total_rows, desc=\"Processing\")\n",
    "\n",
    "# Iterate over each row in the DataFrame\n",
    "for index, row in df.iterrows():\n",
    "    # Apply the qa() function to the concatenated query and store the result in the 'companySentiment' column\n",
    "    df.loc[index, 'impact_score'] = apply_qa(row)\n",
    "    \n",
    "    # Update the progress bar\n",
    "    progress_bar.update(1)\n",
    "    \n",
    "    # Add a time gap between each iteration (e.g., 1 second)\n",
    "#     time.sleep(1)\n",
    "\n",
    "# Close the progress bar\n",
    "progress_bar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae08175",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['isImportant'] = df['impact_score'].apply(lambda x: json.loads(x)['impact_score'] > 5)\n",
    "num_important_rows = df['isImportant'].sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c8971d1a",
   "metadata": {},
   "source": [
    "# Update MongoDB to serve the web-app\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fef9a0d4",
   "metadata": {},
   "source": [
    "### MongoDB Details "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490e2359",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "\n",
    "# Connect to the MongoDB instance, database & collection\n",
    "MONGO_URL=\"YOUR_MONGO_URL\"\n",
    "DB_NAME=\"YOUR_DB_NAME\"\n",
    "COLLECTION = \"YOUR_DB_COLLECTION\"\n",
    "\n",
    "client = MongoClient(MONGO_URL)\n",
    "db = client[DB_NAME]\n",
    "collection = db[COLLECTION]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5a704a6d",
   "metadata": {},
   "source": [
    "### Date Formatting before updating the MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600538ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil import parser\n",
    "import pytz\n",
    "\n",
    "# Assuming your DataFrame is called 'df' and it contains a field 'publishedOn'\n",
    "\n",
    "# Define timezones\n",
    "us_eastern = pytz.timezone('US/Eastern')\n",
    "\n",
    "# Function to convert and format time to EDT\n",
    "def convert_to_edt(time_str):\n",
    "    parsed_time = parser.parse(time_str)\n",
    "    eastern_time = parsed_time.astimezone(us_eastern)\n",
    "    edt_time_format = '%Y-%m-%d %H:%M:%S EDT'\n",
    "    return eastern_time.strftime(edt_time_format)\n",
    "\n",
    "# Create the new field 'publishedOn_EDT'\n",
    "df['publishedOn_EDT'] = df['publishedOn'].apply(convert_to_edt)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4a3e1758",
   "metadata": {},
   "source": [
    "### Add df to a collection in MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd7215c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over each row in the DataFrame\n",
    "for index, row in df.iterrows():\n",
    "    # Get the company sentiment string for the current row\n",
    "    company_sentiments_str = row['companySentiment']\n",
    "    \n",
    "    # Convert the string to a Python object (list of dictionaries)\n",
    "    company_sentiments = json.loads(company_sentiments_str)\n",
    "    \n",
    "    company_names = row['associated_companies']\n",
    "\n",
    "    # Create the MongoDB document\n",
    "    document = {\n",
    "        \"header\": row['header'],\n",
    "        \"sourceUrl\": row['sourceUrl'],\n",
    "        \"publisher\": row['publisher'],\n",
    "        \"publishedOn\": row['publishedOn_EDT'],\n",
    "        \"description\": row['description'],\n",
    "        \"isImportant\": row['isImportant'],\n",
    "        \"imageUrl\": row['imageUrl'],\n",
    "        \"companyNames\": company_names,\n",
    "        \"companySentiment\": company_sentiments,\n",
    "    }\n",
    "\n",
    "    # Insert the document into MongoDB\n",
    "    collection.insert_one(document)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
